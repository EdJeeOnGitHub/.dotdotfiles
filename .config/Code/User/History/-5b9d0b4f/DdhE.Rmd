---
title: "Initial Model Fits"
author: "Ed Jee and Becky Scurlock"
date: '2022-06-18'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = normalizePath(".."), echo = TRUE)
```

```{r, message = FALSE, warning = FALSE, results='hide'}
library(tidyverse)
library(cmdstanr)
library(ggstance)
library(lubridate)
library(survival)
library(flexsurv)
library(tidybayes)
library(tidyr)
library(bayesplot)
library(ggplot2)
library(rstanarm)
library(simsurv)
source("helpers.R")
options(mc.cores = 4)
```

# Load and clean data
```{r}
all_df = read_csv("data/individual_data_full.csv", guess_max = 10000)

subset_df = all_df %>% filter(!str_detect(study, "Quick"))  # No events in Quick et al.

clean_df = subset_df %>%
    select(
        study, 
        event_time_lb,
        event_time_ub,
        follow_up_time, 
        treatment_time, 
        death, 
        wtreatment,
        age_month, 
        precision_evt
    ) %>%
    mutate(
        cens_event_time_lb = if_else(
            death == 0,
            follow_up_time,
            event_time_lb
        ),
        cens_event_time_ub = if_else(
          death == 0,
          follow_up_time,
          event_time_ub
        ),
        left_interval = interval(treatment_time, cens_event_time_lb) %/% days(1), 
        right_interval = interval(treatment_time, cens_event_time_ub) %/% days(1),
    ) %>%
    group_by(study) %>%
    mutate(site_id = cur_group_id()) %>%
    ungroup() %>%
    filter(!is.na(death)) %>%
    mutate(censoring = if_else(death == 0, 0, 
        ifelse(left_interval == right_interval, 1, 3)), 
        right_interval = right_interval + ifelse(left_interval == 0, 1, 0),
        left_interval = left_interval + ifelse(left_interval == 0, 1, 0)) %>%
    filter(!is.na(left_interval) & !is.na(right_interval)) 

head(clean_df)
```

# Fit frequentist survival models to obtain point estimates
```{r}
# Create survival modeling functions
mods = c("exp", "weibull")  # Excluding Gompertz for now due to fitting issues
surv_mod = function(x, mod) {
  # Note: flexsurvspline doesn't work when all observations are either 
  # right-censored or interval censored
  flexsurvreg(Surv(left_interval, right_interval, death, type = "interval")
              ~ as.factor(wtreatment), data = x, dist=mods[mod])
}
poss_surv_mod = possibly(surv_mod, otherwise = NULL)

# Split by study
df_list = clean_df %>%
  select(site_id, left_interval, right_interval, death, wtreatment) %>%
  group_by(site_id) %>%
  group_split()

# Fit survival models
tidy_fits = list()
tidy_fits_hr = list()
for (mod in 1:2) {  # Note: Weibull doesn't converge for some studies
  # Map over separate dfs and fit survival model
  fit_list = df_list %>% map(~poss_surv_mod(x = .x, mod))

  # Map over list of fits
  # imap creates a variable .y that acts as a counter for each list object 
  # _dfr says combine the final results into a dataframe by row   
  fit_list = fit_list %>%
    imap_dfr(~broom::tidy(.x, conf.int = TRUE) %>% mutate(site_id = .y, type = mods[mod])) 
  
  # Tidy up the fits
  tidy_fits[[mod]] = fit_list %>% 
    filter(str_detect(term, "treatment")) %>% 
    mutate(model_type = "Frequentist")
  
  # Convert estimates to hazard ratios and tidy up fits. Reference: 
  # https://wilmarigl.de/wp-content/uploads/2018/01/tutorial_hr_parsurvmodels.pdf
  tidy_fits_hr[[mod]] = fit_list %>% 
    mutate(term = ifelse(str_detect(term, "treatment"), "trt", term)) %>%
    select("site_id", "term", "estimate", "conf.low", "conf.high", "type") %>%
    pivot_wider(id_cols = c("site_id", "type"), names_from = "term", values_from = 
      c("estimate", "conf.low", "conf.high")) # Reshape data
  
  tidy_fits_hr[[mod]] = tidy_fits_hr[[mod]] %>%
    mutate(estimate = exp(estimate_trt),
    conf.low = exp(conf.low_trt), 
    conf.high = exp(conf.high_trt),
    model_type = "Frequentist") %>%
    select("site_id", "estimate", "conf.low", "conf.high", "type", "model_type")
}

# Truncate upper confidence bounds to reasonable levels and remove huge estimates
for (i in 1:2) {
  tidy_fits[[i]]$conf.high = unlist(lapply(tidy_fits[[i]]$conf.high, function(x) min(x, 5)))
  tidy_fits_hr[[i]]$conf.high = 
    unlist(lapply(tidy_fits_hr[[i]]$conf.high, function(x) min(x, 5)))
  tidy_fits_hr[[i]]$estimate = ifelse(tidy_fits_hr[[i]]$estimate < 5, 
    tidy_fits_hr[[i]]$estimate, NA)
}
```

# Make plots
```{r}
site_name = clean_df %>%
  select(study, site_id) %>%
  unique()

tidy_stan_draws = function(stan_draws) {
  stan_draws %>%
  median_qi() %>%
  filter(k == 2 & .variable == "beta") %>%
  to_broom_names() %>% 
  mutate(model_type = "Bayesian")
}

tidy_stan_draws_hr = function(stan_draws) {
  stan_draws %>%
  median_qi() %>%
  filter(k == 2 & .variable == "hazard_ratio") %>%
  to_broom_names() %>% 
  mutate(model_type = "Bayesian")
}

plot_est <- function(compare_fits) {
  # Plot hazard ratios 
  # bayes_plot_hr <- all_tidy_draws_hr[[i]] %>%
  #   left_join(site_name, by = "site_id") %>% 
  #   filter(model_type == "Bayesian") %>%
  #   ggplot(aes(
  #     x = estimate,
  #     xmin = conf.low,
  #     xmax = conf.high,
  #     y = study,
  #     colour = factor(site_id)
  #   )) +
  #   geom_pointrangeh() +
  #   geom_vline(xintercept =  1, linetype = "longdash") +
  #   theme_bw()
  # print(bayes_plot_hr)
  
  # Plot Bayesian vs. frequentist models
  both_plot <- compare_fits %>%
    ggplot(aes(
      x = estimate,
      xmin = conf.low,
      xmax = conf.high,
      y = study,
      colour = model_type
    )) +
    geom_pointrangeh(position = position_dodge2v(0.5)) +
    geom_vline(xintercept = 1, linetype = "longdash") +
    theme_bw() + ggtitle(paste("Model:", 
    ifelse(compare_fits$type[1] == "exp",
    "Exponential", "Weibull"))) + xlab("HR Estimate") + 
    ylab("Study") + scale_color_discrete(name = "Model Type")
  print(both_plot)
}

plot_function = function(comp_df) {
  p = comp_df %>%
    ggplot(aes(
      x = estimate,
      xmin = conf.low,
      xmax = conf.high,
      y = study,
      colour = model_type
    )) +
    geom_pointrangeh(
      position = position_dodge2v(0.5)
    ) +
    geom_vline(
      xintercept = 1, linetype = "longdash"
    ) +
    theme_bw()
    return(p)
}
```

# Code for simulation
```{r}
# Fit Bayesian survival model
surv_model = cmdstan_model("survival-stan/hierarchical-survival.stan")
mods = c("exp", "weibull")  # Excluding Gompertz for now due to fitting issues

# Generate Data (exponential)
surv_sim <- function(mod, logHR, N = 200) {
  x = data.frame(id = 1:N, trt = rbinom(N, 1, 0.5))
  if (mod == 1) {
    df_sim = simsurv(dist = mods[mod], lambdas = 0.1, x = x, 
      betas = c(trt = logHR), maxt = 5)
  } else if (mod == 2) {
    df_sim = simsurv(dist = mods[mod], lambdas = 0.1, gammas = 1.5, x = x, 
      betas = c(trt = logHR), maxt = 5) 
  }
  df_sim = df_sim %>% merge(x)
  
  # Fit frequentist survival model
  # Create survival modeling functions
  fit = flexsurvspline(Surv(eventtime, status, type = "right") ~ as.factor(trt), 
    data = df_sim)
  fit = broom::tidy(fit, conf.int = TRUE) %>% mutate(type = mods[mod])
  
  # Convert estimates to hazard ratios and tidy up fits. Reference: 
  # https://wilmarigl.de/wp-content/uploads/2018/01/tutorial_hr_parsurvmodels.pdf
  tidy_fits_hr = fit %>% mutate(term = ifelse(str_detect(term, "trt"), "trt", term)) %>%
    select("term", "estimate", "conf.low", "conf.high", "type") %>%
    mutate(term = str_replace(term, "gamma1", "shape")) %>%
    filter(str_detect(term, "trt"))
  
  tidy_fits_hr = tidy_fits_hr %>%
    mutate(estimate = exp(estimate),
    conf.low = exp(conf.low), 
    conf.high = exp(conf.high),
    model_type = "Frequentist")
  
  tidy_fits_hr = tidy_fits_hr %>%
    select("estimate", "conf.low", "conf.high", "type", "model_type")
  
  stan_data = list(
      N = nrow(df_sim),
      J = 1,
      nc = 2,
      nsc = 100,
      site = rep(1, N), 
      X = df_sim %>% 
        mutate(const = 1) %>% 
        select(const, trt) %>% 
        as.matrix(),
      censoring = df_sim$status,
      interval_left = df_sim$eventtime,
      interval_right = df_sim$eventtime,
      model_type = 1
  )
  
  surv_fit = surv_model$sample(stan_data, refresh = 0)
  stan_draws = surv_fit %>% gather_draws(beta[logHR_id, k],
    hazard_ratio[logHR_id, k])
  all_tidy_draws_hr = tidy_stan_draws_hr(stan_draws)
  fits_hr = bind_rows(tidy_fits_hr, all_tidy_draws_hr) %>%
    mutate(logHR = logHR)
  
  return(fits_hr)
}

plot_sim <- function(fits_hr) {
  # Plot Bayesian vs. frequentist models (hazard ratios)
  both_plot_hr <- fits_hr %>%
    ggplot(aes(
      x = estimate,
      xmin = conf.low,
      xmax = conf.high,
      y = logHR,
      colour = model_type
    )) +
    geom_pointrangeh(position = position_dodge2v(0.5)) +
    geom_vline(xintercept = 1, linetype = "longdash") +
    theme_bw() + ggtitle(paste("Model:", ifelse(fits_hr$type[1] == "exp",
    "Exponential", "Weibull"))) + xlab("HR Estimate") +
    ylab("Study") + scale_color_discrete(name = "Model Type")
  
  print(both_plot_hr)
}

logHRs = c(-1, -0.5, 0, 0.5, 1)
fits_hr_exp = map(logHRs, function(x) surv_sim(1, x))
fits_hr_wei = map(logHRs, function(x) surv_sim(2, x))
```

```{r}
plot_sim(bind_rows(fits_hr_exp))
plot_sim(bind_rows(fits_hr_wei))
```

# Fit Bayesian models
```{r, message = FALSE, warning = FALSE}
# stan_df = clean_df %>%
#   group_by(study) %>%
#   mutate(n = n()) %>%
#   ungroup() %>%
#   filter(n > quantile(n, 0.8)) %>%
#   group_by(study) %>%
#   mutate(site_id = cur_group_id()) %>%
#   ungroup()
stan_df = clean_df  %>%  group_by(study) %>%sample_frac(0.3) %>% ungroup() # filter(str_detect(study, "Haushofer")) # to run faster
surv_model = cmdstan_model("survival-stan/hierarchical-survival.stan")
options(mc.cores = 4)
stan_draws = list()
for (i in c(1)) {   # Gompertz (3) doesn't currently work
  i = 2
  stan_data = list(
      N = nrow(stan_df),
      J = length(unique(stan_df$study)),
      nc = 2,
      site = stan_df$site_id, 
      X = stan_df %>% 
        mutate(const = 1) %>% 
        select(const, wtreatment) %>% 
        as.matrix(),
      censoring = stan_df$censoring,
      interval_left = stan_df$left_interval,
      interval_right = stan_df$right_interval,
      model_type = i
  )
  
  surv_fit = surv_model$sample(stan_data)  # adapt_delta=0.95
  stanfit <- rstan::read_stan_csv(surv_fit$output_files())
shinystan::launch_shinystan(stanfit)
  # print(surv_fit$loo())  # Compute LOO
  stan_draws[[i]] = surv_fit %>% gather_draws(beta[site_id, k],
    hazard_ratio[site_id, k])  # y_rep[n]
}
```

# Code for actual models
```{r}
stan_draws = list()
stan_draws[[1]] = readRDS("data/stan_draws_exp.rds")
# stan_draws[[2]] = readRDS("stan_draws_exp.rds")
```

```{r}
stan_draws_sub = map(stan_draws, ~ filter(.x, .variable != "y_rep"))
all_tidy_draws = map(stan_draws_sub, tidy_stan_draws)
all_tidy_draws_hr = map(stan_draws_sub, tidy_stan_draws_hr)
comp_dfs = map2(tidy_fits, all_tidy_draws, ~bind_rows(.x, .y) %>%
  left_join(site_name, by = "site_id"))

# Adding names
comp_dfs = comp_dfs %>%
  map(mutate, estim_type = "untransformed")
comp_hr_dfs = map2(tidy_fits, all_tidy_draws_hr, ~bind_rows(.x, .y) %>%
  left_join(site_name, by = "site_id"))
comp_hr_dfs = comp_hr_dfs %>%
  map(mutate, estim_type = "hazard")

comp_plots = map(comp_dfs, plot_function)
comp_hr_plots = map(comp_hr_dfs, plot_function)

# No frequency estimate
comp_nf_p = map(comp_dfs, ~ filter(.x, model_type == "Bayesian") %>% plot_function())
comp_hr_nf_p = map(comp_hr_dfs, ~ filter(.x, model_type == "Bayesian") %>% plot_function())

compare_fits_hr = list()
for (i in 1:length(stan_draws)) {
  compare_fits_hr[[i]] = 
    bind_rows(tidy_fits_hr[[i]], all_tidy_draws_hr[[i]]) %>%
    left_join(site_name, by = "site_id") 
}
all_plots = map(compare_fits_hr, plot_est)
```
```{r}
# Plot against Bayes OR results from original meta-analysis
df_or = data.frame(site_id = 1:14, estimate = c(1.04, 0.00, 0.30, 2.09, 0.30,
  0.95, 0.68, 0.80, 1.72, 0.86, 0.82, 0.49, 0.55, 0.00), 
  conf.low = c(0.11, 0.00, 0.12, 0.48, 0.11, 0.63, 0.26, 0.46, 0.12, 0.53, 
  0.53, 0.09, 0.18, 0.00),
  conf.high = c(10.35, 1.25, 0.71, 10.72, 0.71, 1.42, 1.70, 1.39, 40.64, 
  1.35, 1.25, 2.14, 1.78, 0.59), type = "exp", model_type = "Bayes OR")

all_tidy_draws_hr_2 = all_tidy_draws_hr %>% 
  map(~ mutate(.x, model_type = "Bayes HR"))
tidy_fits_hr_2 = tidy_fits_hr %>% 
  map(~ mutate(.x, model_type = "Frequentist HR"))
df_or$conf.high[which(df_or$conf.high > 5)] = 5
# compare_fits_hr = compare_fits_hr %>% map(~ bind_rows(df_or))

compare_fits_hr = list()
for (i in 1:2) {
  i = 1
  compare_fits_hr[[i]] = 
    bind_rows(tidy_fits_hr_2[[i]], all_tidy_draws_hr_2[[i]], df_or) %>%
    left_join(site_name, by = "site_id") %>% mutate(type = mods[i])
}

all_plots_2 = map(compare_fits_hr, plot_est)
```

# Plot model predictions
```{r}
tidy_stan_draws_beta = function(stan_draws) {
  stan_draws %>%
  median_qi() %>%
  filter(.variable == "hazard_ratio") %>%
  to_broom_names() %>% 
  select(estimate, k, site_id) %>% 
  pivot_wider(id_cols = site_id, names_from = k, values_from = estimate) %>% 
  rename(estimate_1 = "1", estimate_2 = "2") %>%
  mutate(estimate_2 = log(estimate_2)) 
}

all_tidy_draws_beta = map(stan_draws_sub, tidy_stan_draws_beta) 

set.seed(999)
mod = 1
ids = unique(prep_stan_df$site_id)
ids = setdiff(ids, c(2,9))  # Exclude Chiller + Luby
prep_stan_df = prep_stan_df %>% 
  left_join(all_tidy_draws_beta[[mod]])

pred_plot <- function(id) {
  x = prep_stan_df %>%
      filter(site_id == id) 
  lambdas = unique(x$estimate_1)
  logHR = unique(x$estimate_2)
  x = x %>%
      select(wtreatment) %>%
      mutate(id = 1:nrow(x))
  df_sim = simsurv(dist = mods[mod], lambdas = lambdas, x = x, 
    betas = c(wtreatment = logHR), interval = c(1e-08, 2100), maxt = 2000) %>%
    left_join(x)
  
  km_fit <- survfit(Surv(eventtime, status, type = "right") ~ 
    as.factor(wtreatment), data = df_sim, type = "kaplan-meier")
  
  # Plot Kaplan-Meier curves
  print(autoplot(km_fit) + xlab("Days After Treatment") + 
    ylab("Survival Prob.") + ggtitle(site_name$study[which(site_name$site_id == id)]) +
    theme_bw()) + 
    theme(plot.title=element_text(size=10), axis.title=element_text(size=8)) +
    scale_fill_discrete(name = "Group") + 
    scale_color_discrete(name = "Group")
}

ggarrange(plotlist = map(ids, pred_plot), nrow = 3, ncol = 3,
  common.legend = TRUE, legend="bottom")
```

# Fit frequentist models with age covariate 
```{r}
# Filter studies with no age data
clean_df_sub = clean_df %>% 
  filter(!str_detect(study, "Humphrey")) %>%
  filter(!str_detect(study, "Semenza")) %>%
  filter(!(str_detect(study, "Luby") & str_detect(study, "2018"))) %>% 
  mutate(age_month_std = (age_month - mean(age_month, na.rm = TRUE)) / 
  sd(age_month, na.rm = TRUE)) 

# Redefine time variables in terms of age (and convert from days to months)
clean_df_sub$left_interval_age = clean_df_sub$age_month + (clean_df_sub$left_interval/30)
clean_df_sub$right_interval_age = clean_df_sub$age_month + (clean_df_sub$right_interval/30)
clean_df_sub$left_interval_age[which(clean_df_sub$left_interval_age < 0)] = 0

# Round to avoid errors in survfit
clean_df_sub$left_interval_age = round(clean_df_sub$left_interval_age, 3)
clean_df_sub$right_interval_age = round(clean_df_sub$right_interval_age, 3)

clean_df_sub = clean_df_sub %>% 
  mutate(censoring = ifelse(death == 0, 0, 
    ifelse(left_interval_age == right_interval_age, 1, 3)),
    right_interval_age = right_interval_age + ifelse(left_interval_age == 0, 1, 0),
    left_interval_age = left_interval_age + ifelse(left_interval_age == 0, 1, 0))

site_name_sub = clean_df_sub %>%
  select(study, site_id) %>%
  unique() %>% 
  arrange(site_id) %>%
  mutate(site_id = 1:11)

# Create survival modeling functions
mods = c("exp", "weibull")  # Excluding Gompertz for now due to fitting issues
surv_mod = function(x, mod) {
  # Note: flexsurvspline doesn't work when all observations are either 
  # right-censored or interval censored
  flexsurvreg(Surv(left_interval_age, right_interval_age, death, type = "interval")
    ~ as.factor(wtreatment), data = x, dist=mods[mod])
}
poss_surv_mod = possibly(surv_mod, otherwise = NULL)

# Split by study
df_list = clean_df_sub %>%
  select(site_id, left_interval_age, right_interval_age, death, wtreatment) %>%
  group_by(site_id) %>%
  group_split()

# Fit survival models
tidy_fits = list()
tidy_fits_hr = list()
for (mod in 1:2) {  # Note: Weibull doesn't converge for some studies
  # Map over separate dfs and fit survival model
  fit_list = df_list %>% map(~poss_surv_mod(x = .x, mod))

  # Map over list of fits
  # imap creates a variable .y that acts as a counter for each list object 
  # _dfr says combine the final results into a dataframe by row   
  fit_list = fit_list %>%
    imap_dfr(~broom::tidy(.x, conf.int = TRUE) %>% mutate(site_id = .y, type = mods[mod])) 
  
  # Tidy up the fits
  tidy_fits[[mod]] = fit_list %>% 
    filter(str_detect(term, "treatment")) %>% 
    mutate(model_type = "Frequentist")
  
  # Convert estimates to hazard ratios and tidy up fits. Reference: 
  # https://wilmarigl.de/wp-content/uploads/2018/01/tutorial_hr_parsurvmodels.pdf
  tidy_fits_hr[[mod]] = fit_list %>% 
    mutate(term = ifelse(str_detect(term, "treatment"), "trt", term)) %>%
    select("site_id", "term", "estimate", "conf.low", "conf.high", "type") %>%
    pivot_wider(id_cols = c("site_id", "type"), names_from = "term", values_from = 
      c("estimate", "conf.low", "conf.high")) # Reshape data
  
  tidy_fits_hr[[mod]] = tidy_fits_hr[[mod]] %>%
    mutate(estimate = exp(estimate_trt),
    conf.low = exp(conf.low_trt), 
    conf.high = exp(conf.high_trt),
    model_type = "Frequentist") %>%
    select("site_id", "estimate", "conf.low", "conf.high", "type", "model_type")
}

# Truncate upper confidence bounds to reasonable levels and remove huge estimates
for (i in 1:2) {
  tidy_fits[[i]]$conf.high = unlist(lapply(tidy_fits[[i]]$conf.high, function(x) min(x, 5)))
  tidy_fits_hr[[i]]$conf.high = 
    unlist(lapply(tidy_fits_hr[[i]]$conf.high, function(x) min(x, 5)))
  tidy_fits_hr[[i]]$estimate = ifelse(tidy_fits_hr[[i]]$estimate < 5, 
    tidy_fits_hr[[i]]$estimate, NA)
}
```

# Fit Bayesian models with age covariate 
```{r, message = FALSE, warning = FALSE}
prep_stan_df = clean_df_sub %>%  # sample_frac(0.1) %>% # to run faster
  mutate(const = 1) %>% 
  select(const, wtreatment, left_interval_age, right_interval_age, study, site_id, censoring) %>%
  # mutate(age_month = ifelse(age_month <= 12, 1, 0)) %>%
  na.omit() %>%
  group_by(site_id) %>%
  mutate(reindex_site_id = cur_group_id()) %>%
  ungroup()

surv_model = cmdstan_model("survival-stan/hierarchical-survival.stan")

stan_draws_age = list()
i = 1
# for (i in 1:2) {   # Gompertz (3) doesn't currently work

stan_data = list(
  interval_left = prep_stan_df$left_interval_age,
  interval_right = prep_stan_df$right_interval_age,
  N = nrow(prep_stan_df),
  J = length(unique(prep_stan_df$study)),
  nc = 2,
  site = prep_stan_df$reindex_site_id, 
  X = prep_stan_df %>%
    select(const, wtreatment) %>%
    as.matrix(),
  censoring = prep_stan_df$censoring,
  model_type = i
)

surv_fit = surv_model$sample(stan_data)
# print(surv_fit$loo())  # Compute LOO
stan_draws_age[[i]] = surv_fit %>% gather_draws(beta[site_id, k],
  hazard_ratio[site_id, k])  # y_rep[n]

#}
```
```{r}
# Reset site indices
# stan_draws_age = stan_draws_age %>% map(~ rename(reindex_site_id = site_id) %>%
#   left_join(prep_stan_df %>% 
#   summarize(site_id = unique(site_id), reindex_site_id = unique(reindex_site_id))) %>% 
#   select(-c(reindex_site_id)))  # HOW TO DO THIS?

# Filter and clean MCMC draws
stan_draws_age_sub = map(stan_draws_age, ~ filter(.x, .variable != "y_rep"))
all_tidy_draws = map(stan_draws_age_sub, tidy_stan_draws)
all_tidy_draws_hr = map(stan_draws_age_sub, tidy_stan_draws_hr) 
comp_dfs = map2(tidy_fits, all_tidy_draws, ~bind_rows(.x, .y) %>%
  left_join(site_name_sub, by = "site_id"))

# Adding names
comp_dfs = comp_dfs %>%
  map(mutate, estim_type = "untransformed")
comp_hr_dfs = map2(tidy_fits, all_tidy_draws_hr, ~bind_rows(.x, .y) %>%
  left_join(site_name_sub, by = "site_id"))
comp_hr_dfs = comp_hr_dfs %>%
  map(mutate, estim_type = "hazard")

comp_plots = map(comp_dfs, plot_function)
comp_hr_plots = map(comp_hr_dfs, plot_function)

# No frequency estimate
comp_nf_p = map(comp_dfs, ~ filter(.x, model_type == "Bayesian") %>% plot_function())
comp_hr_nf_p = map(comp_hr_dfs, ~ filter(.x, model_type == "Bayesian") %>% plot_function())

compare_fits_hr = list()
for (i in 1:2) {
  i = 1
  compare_fits_hr[[i]] = 
    bind_rows(tidy_fits_hr[[i]], all_tidy_draws_hr[[i]]) %>%
    left_join(site_name_sub, by = "site_id") 
}
all_plots = map(compare_fits_hr, plot_est)
```

# Plot model predictions
```{r}
tidy_stan_draws_age_beta = function(stan_draws) {
  stan_draws %>%
  median_qi() %>%
  filter(.variable == "hazard_ratio") %>%
  to_broom_names() %>% 
  select(estimate, k, site_id) %>% 
  pivot_wider(id_cols = site_id, names_from = k, values_from = estimate) %>% 
  rename(estimate_1 = "1", estimate_2 = "2") %>%
  mutate(estimate_2 = log(estimate_2)) %>% 
  left_join(site_name_sub) %>% 
  select(-site_id) %>% 
  left_join(site_name) %>% 
  select(-study)
}

all_tidy_draws_beta = map(stan_draws_age_sub, tidy_stan_draws_age_beta) 

set.seed(999)
mod = 1
ids = unique(prep_stan_df$site_id)
ids = setdiff(ids, c(2,9))  # Exclude Chiller + Luby
prep_stan_df = prep_stan_df %>% 
  left_join(all_tidy_draws_beta[[mod]])
for (id in ids) {
  x = prep_stan_df %>%
      filter(site_id == id) 
  lambdas = unique(x$estimate_1)
  logHR = unique(x$estimate_2)
  x = x %>%
      select(wtreatment) %>%
      mutate(id = 1:nrow(x))
  df_sim = simsurv(dist = mods[mod], lambdas = lambdas, x = x, 
    betas = c(wtreatment = logHR), interval = c(1e-08, 2100), maxt = 2000) %>%
    left_join(x)
  
  km_fit <- survfit(Surv(eventtime, status, type = "right") ~ 
    as.factor(wtreatment), data = df_sim, type = "kaplan-meier")
  
  # Plot Kaplan-Meier curves
  print(autoplot(km_fit) + xlab("Time After Treatment (Days)") + 
    ylab("Survival Probability") + ggtitle(paste("K-M:",
    site_name$study[which(site_name$site_id == id)])) + theme_bw())

}
```

```{r}
# Get posterior predictive draws
tidy_stan_draws_pp = function(stan_draws) {
  stan_draws = stan_draws %>%
  filter(.variable == "y_rep") %>%
  to_broom_names() 
  
  # Return matrix with draws (4 chains with 1000 draws per chain)
  return(matrix(stan_draws$estimate, 1000*4, nrow(stan_df), byrow = FALSE))
}

all_y_rep = map(stan_draws, tidy_stan_draws_pp)
y = Surv(stan_df$left_interval, stan_df$right_interval, stan_df$death, 
  type = "interval")

for (i in 1:2) {
  yrep = all_y_rep[[i]]
  yrep = ifelse(yrep > 1e4, 1e4, yrep)  # Truncate draws at 10,000
  y = as.vector(y)[1:ncol(yrep)]  # Convert censored values to numeric
  
  color_scheme_set("brightblue")
  print(ppc_dens_overlay(y, yrep[900:1000,]))
  print(ppc_hist(y, yrep[901:905,]))
}
```