\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{float}
\author{Ed Jee}
\title{Individual Level Power Simulations}

\begin{document}

\maketitle



\section*{Creating Time Series Data}


The file "code/clean-monthly-xl-data.R" cleans the cohort-year-month observations 
supplied by IRD and generates a time series of monthly number of vaccination by 
cohort birth year. Figure \ref{fig:n-penta} shows the number of vaccinated 
children vaccinated per month.  Cohorts get "phased out" and after a certain 
window very few "catch-up" vaccines are administered. In Figure \ref{fig:p-penta}  
the effect of Covid is clear in the 2020 cohort - vaccination rates actually fall 
(more children are born over the year than are being vaccinated) for some months in 
2020.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{penta-1-vax-n-example.png}
    \caption{Number of Vaccinations Administered per month, by birth cohort}
    \label{fig:n-penta}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{penta-1-vax-rate-example.png}
    \caption{Fraction of Living Childred Vaccinated per month, by birth cohort}
    \label{fig:p-penta}
\end{figure}


\section*{Power Simulations}

Our power simulation procedure can be summarised as:

\begin{itemize}
    \item Estimate a model $Q(\underbrace{\beta}_0, \theta | Y_{t-1}, z_{t-1})$ using historical data, $Y_{t-1}$, and historical (unobserved) shocks, $z_{t-1}$. 
    Where $\beta= 0$ indicates a 0 treatment effect as treatment is never implemented historically.
    \item Use this generative model to create counterfactual simulated draws across different $\beta$s. 
    That is, draw $z_t \sim F_z$ and sample  $\tilde{Y}_t \sim \hat{Q}_t(\beta, \theta | Y_{t-1}, z_t), \beta \in \Gamma$.
\end{itemize}


In words, we normally fit some model - maybe OLS, maybe something with random 
effects - and use fitted means and variances as plug in values in some DGP and then draw 
district, time, vaccine shocks etc.
    


Instead, we're going to do everything in one step - estimate a fully Bayesian model 
and draw from the \textit{posterior predictive} distribution. This is identical to 
generating some data from a DGP and then adding random noise except we can ensure 
the model is internally coherent. That is, there's no chance of creating vaccination 
probabilites above 1 or below 0 for instance and we can directly compare simulated 
draws to realised draws to inspect goodness of fit.


\subsection*{Model Estimation and Generation}


We focus only on data from the 2019 cohort since Covid introduced some unusual  
dynamics in 2020 and 2021 has mostly incomplete data. We estimate:

\begin{align*}
     \mu_{dtv} &= \alpha_{dv} + \gamma_{tv} \\
     \# \textit{vaxxed}_{dtv} &\sim NB\left(\frac{\mu_{dtv}^2}{\sigma^2_{v} - \mu_{dtv}}, \frac{\sigma^2_{v} - \mu_{dtv}}{\sigma^2_{v}} \right), \forall v \in V \\
     \alpha_{dv}, \gamma_{tv} &\sim N(\mu_0, \sigma_0) \\
\end{align*}

I.e. a negative binomial regression\footnote{Basically, Poisson regression for count data but 
we allow for "overdispersion" and the variance isn't pinned down by the mean. This is essential for our case 
due to very large overdispersion in the data.} with 
parameters $p, r$ which I've reparametrised in terms of a mean and variance here. 
We've replaced traditional random effects with hierarchical varying intercepts $\alpha, \gamma$.



Then, because we want to convert this into individual level data we draw from the 
posterior predictive distribution to generate $\# vaxxed_{dtv}^b$ for $b = 1, ..., B$ 
where $B$ indicates the number of simulated draws - Figure \ref{fig:pp} shows how 
well our simulated draws match the underlying data whilst also reflecting parameter 
uncertainty and predictive "noise".  Next, we convert this into a 
a function of treatment by defining: 
\begin{align*}
    \# vaxxed_{dtv}^b(\beta) = \# vaxxed_{dtv}^b \times (1 + \beta \times D_{dtv}) 
\end{align*}

That is, we scale up the number vaccinated by $\beta$ if they district is rolled 
into treatment.

Finally, we convert $\# vaxxed_{dtv}^b(\beta)$ into a probability of vaccination 
for an individual by making an assumption about monthly births to create $p_{dtv}^b(\beta)$ 
and use this probability to generate individual level data by drawing from the 
Bernoulli:
\begin{align*}
\textit{indiv vaxxed}_{idtv} \sim Ber(p^b_{dtv})
\end{align*} 


To keep things simple I only draw data for one birth cohort and simulate their 
outcomes across 3 years. This is going to have a downside we will see later.

\begin{figure}[htbp]
    \centering
   \includegraphics[scale=0.5]{realised-sim-draws.png} 
    \caption{Posterior Predictive Draws of \# Vaccinated}
    \label{fig:pp}
\end{figure}


\section*{Power Estimation}


Once we have our generative draws in hand for each value of $\beta$ we can simply 
specify our sampling plan (who ends up in our regression) and fit regression models 
to our heart's content. For each $\beta$ value and sampling plan we estimate how many simulated draws 
are significant to calculate power levels.


\section*{Power Results}

    Parallel Trends using Not Yet Treated Units:
    \begin{align*}
        E\left[\Delta_t | G = g\right] &= 
        E\left[
            \Delta_t | \underbrace{D_s = 0, G \neq g}_\text{Units not yet treated.} 
        \right], \forall g = 2, ... \mathcal{T}, t = 2, ..., \mathcal{T}
    \end{align*}

    i.e. in absence of initial treatment in period $g$, units would 
    have same outcome path as those yet to be treated. 





    Suggests very simple analogue estimator:

    \begin{align*}
       \hat{ATT}(g,t) = \frac{1}{N_g} \sum_{i=1}^{N_g}  (Y_{t,i} - Y_{g-1,i}) \mathbb{I}\{G_{gi} = 1\} -
       \frac{1}{N_{nyt(g)}} \sum_{i=1}^{N_{nyt(g)}} (Y_{t,i} - Y_{g-1,i})\mathbb{I}\{nyt(g)_i\} 
    \end{align*}




\end{document}